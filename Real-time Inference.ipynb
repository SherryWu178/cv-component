{"cells":[{"cell_type":"markdown","metadata":{"id":"Xe7c9ihUVeam"},"source":["# Wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22023,"status":"ok","timestamp":1715553158507,"user":{"displayName":"imaging-physcomp","userId":"09199835669596966042"},"user_tz":240},"id":"dVd2sw6LOBMZ","outputId":"633049d0-f8e3-4233-e6d0-e86e8423a5f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.3/277.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install wandb -qU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SGaTLmH7A2o"},"outputs":[],"source":["import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2483,"status":"ok","timestamp":1715553161953,"user":{"displayName":"imaging-physcomp","userId":"09199835669596966042"},"user_tz":240},"id":"cpvQrTdE6j0n","outputId":"2b1abe4f-f9b2-4012-fbea-aaf265b5ef28"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["wandb.login(key=\"fd03f0adf38ef723e0db64fb17c11ea8efa4b4a6\") # Use your own wandb api key"]},{"cell_type":"markdown","metadata":{"id":"P9fYcrNhVgKi"},"source":["# Mount to Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205280,"status":"ok","timestamp":1715553367228,"user":{"displayName":"imaging-physcomp","userId":"09199835669596966042"},"user_tz":240},"id":"njCrl8UP9S8d","outputId":"49325f7e-5e7e-4301-d163-6df710abb643"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":721,"status":"ok","timestamp":1715553367942,"user":{"displayName":"imaging-physcomp","userId":"09199835669596966042"},"user_tz":240},"id":"_wqW9Xz79XL1","outputId":"7d7a9f8f-028f-4236-a9b4-a9c085021f2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/12qdxIhrJkYThSDH6ulLJ4IaUDG4pGrFG/RA_Daragh_CV_Arduino/cv-component/q1_q2_classification\n","/content/drive/.shortcut-targets-by-id/12qdxIhrJkYThSDH6ulLJ4IaUDG4pGrFG/RA_Daragh_CV_Arduino/cv-component/q1_q2_classification\n"]}],"source":["%cd  /content/drive/MyDrive/online arduino kit - cv group/cv-component/q1_q2_classification\n","!pwd"]},{"cell_type":"markdown","metadata":{"id":"-ewT-FEZPsmP"},"source":["# Camera as income video stream\n","\n","**Directly use the connected camera as input source and give prediction in real time.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1YzTo5EP1bh"},"outputs":[],"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5-L5sj8R2-u"},"outputs":[],"source":["def js_to_image(js_reply):\n","    \"\"\"\n","    Params:\n","            js_reply: JavaScript object containing image from webcam\n","    Returns:\n","            img: OpenCV BGR image\n","    \"\"\"\n","    # decode base64 image\n","    image_bytes = b64decode(js_reply.split(',')[1])\n","    # convert bytes to numpy array\n","    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","    # decode numpy array into OpenCV BGR image\n","    img = cv2.imdecode(jpg_as_np, flags=1)\n","    from PIL import Image\n","    pil_img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","    return pil_img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AfWT_2RlPu19"},"outputs":[],"source":["# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","\n","    var pendingResolve = null;\n","    var shutdown = false;\n","\n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = nuleel;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","\n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","\n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","\n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","\n","\n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","    //   stream = await navigator.mediaDevices.getUserMedia(\n","    //       {video: { facingMode: \"environment\"}});\n","      stream = await navigator.mediaDevices.getUserMedia({ video: {\n","            deviceId: 0\n","        } });\n","\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","\n","      const instruction = document.createElement('div');\n","      instruction.innerHTML =\n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","\n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","\n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","\n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","\n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","\n","      return {'create': preShow - preCreate,\n","              'show': preCapture - preShow,\n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","\n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1715553377107,"user":{"displayName":"imaging-physcomp","userId":"09199835669596966042"},"user_tz":240},"id":"HVbHMupSl0-0","outputId":"f22b20be-d49a-4d84-fd73-766d52af4a14"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/.shortcut-targets-by-id/12qdxIhrJkYThSDH6ulLJ4IaUDG4pGrFG/RA_Daragh_CV_Arduino/cv-component/q1_q2_classification'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}],"source":["pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BA8XBWgBP5aR"},"outputs":[],"source":["import torch\n","import torchvision.transforms as transforms\n","import os\n","import cv2\n","\n","#### CHANGE ACCORDINGLY###\n","NUM_CLASSES = 10 # CHANGE THIS BASED ON THE NUMBER OF CLASS!\n","MODEL_PATH = \"../checkpoints/0501_camera_frames_aug3_rotate+relight/checkpoint-10.pth\" # Path to the model checkpoint\n","# MODEL_PATH = \"../checkpoints/0501_camera_frames_aug1_no_aug/checkpoint-10.pth\"\n","# MODEL_PATH = \"../checkpoints/0508_camera_frames_v3_aug1_relight_1+lr0.005_stepsize=5/checkpoint-10.pth\"\n","# MODEL_PATH = \"../checkpoints/0508_camera_frames_v1_aug1_relight_1+lr0.001/checkpoint-10.pth\"\n","#### CHANGE ACCORDINGLY###\n","\n","\n","def load_model(model_path):\n","    # Assuming YourModelClass is defined in the file containing the model\n","    from train_q2 import ResNet\n","\n","    # Instantiate your model class\n","    model = ResNet(NUM_CLASSES)\n","\n","    # Load the trained model weights\n","    if os.path.exists(model_path):\n","        model.load_state_dict(torch.load(model_path))\n","    else:\n","        raise FileNotFoundError(f\"Model file '{model_path}' not found.\")\n","\n","    # Set the model to evaluation mode\n","    model.eval()\n","\n","    return model\n","\n","# Define transformations for input images\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Resize to match model's expected input size\n","    transforms.ToTensor(),  # Convert image to tensor\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.5, 0.5, 0.5]),  # Normalize\n","])\n","\n","# Load the model\n","\n","model = load_model(MODEL_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"id":"jBAP_CkbQAMZ","outputId":"f2a4a06e-8373-406b-8c40-7c1ee16f6b8a"},"outputs":[{"data":{"text/html":["7: 0.44370758056640625<br>9: 0.22841958999633788<br>3: 0.12915075302124024"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0\n","last = -1\n","\n","from IPython.display import display, HTML, clear_output\n","import time\n","\n","# Function to update and display text dynamically\n","def update_text(indices, confidence):\n","\n","    text = '<br>'.join([f\"{indices[i].item()}: {confidence[i].item()/100}\" for i in range(3)])\n","    display(HTML(text))\n","    clear_output(wait=True)\n","\n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    pil_image = js_to_image(js_reply[\"img\"])\n","\n","    # Apply transformations\n","    image = transform(pil_image)\n","    image = image.unsqueeze(0)  # Add batch dimension\n","\n","    # Perform inference\n","    with torch.no_grad():\n","        output = model(image)\n","\n","    # Get the predicted label\n","    # print(output.shape)\n","    confidence = (torch.softmax(output, -1) * 100).squeeze()\n","    confidence, indices = confidence.sort(descending = True)[:3]\n","    # _, predicted = torch.max(output, 1)\n","    # send_osc_message(unity_ip, unity_port, osc_address, predicted.item())\n","    update_text(indices, confidence)\n","    time.sleep(1)  # Wait for 1 second\n","    last = indices[0].item()\n"]},{"cell_type":"markdown","source":["You ma"],"metadata":{"id":"DsCx18hRCeyI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gm0EbjGu0HmY"},"outputs":[],"source":["import requests\n","\n","\n","def send_to_unity(number):\n","    #### CHANGE ACCORDINGLY###\n","    ngrok_url = \"https://732d-128-237-82-12.ngrok-free.app\" # Ngrok URL generated for your service\n","    #### CHANGE ACCORDINGLY###\n","\n","    # Integer representing the class\n","    data = {'number': number}  # Example data to send\n","\n","    # Send integer to the second service\n","    response = requests.post(ngrok_url, json=data)\n","\n","    # Check response\n","    if response.status_code == 200:\n","        print(\"Integer sent successfully!\")\n","    else:\n","        print(\"Failed to send integer. response code {}\".format(response.status_code))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5hvBBmDNf1Fw"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"qD2Pj0_WDdmn"},"source":["# Single image prediction\n","\n","**You will be prompted to provide the link to the image.**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16808,"status":"ok","timestamp":1711813900972,"user":{"displayName":"Sherry Wu","userId":"09653634958685977002"},"user_tz":240},"id":"Kl3k5tlEDfNO","outputId":"4ccfa040-b571-4e29-dd12-2d18fc7c46b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Traceback (most recent call last):\n","  File \"/content/drive/.shortcut-targets-by-id/12qdxIhrJkYThSDH6ulLJ4IaUDG4pGrFG/RA_Daragh_CV_Arduino/cv-component/q1_q2_classification/inference.py\", line 41, in <module>\n","    model = load_model(args.model_path)\n","  File \"/content/drive/.shortcut-targets-by-id/12qdxIhrJkYThSDH6ulLJ4IaUDG4pGrFG/RA_Daragh_CV_Arduino/cv-component/q1_q2_classification/inference.py\", line 18, in load_model\n","    model.load_state_dict(torch.load(model_path))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1026, in load\n","    return _load(opened_zipfile,\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1438, in _load\n","    result = unpickler.load()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1408, in persistent_load\n","    typed_storage = load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 1382, in load_tensor\n","    wrap_storage=restore_location(storage, location),\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 391, in default_restore_location\n","    result = fn(storage, location)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 266, in _cuda_deserialize\n","    device = validate_cuda_device(location)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 250, in validate_cuda_device\n","    raise RuntimeError('Attempting to deserialize object on a CUDA '\n","RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n"]}],"source":["! python q1_q2_classification/inference.py \\\n","    --model_path ./checkpoint-model-epoch10_11classes.pth"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["Xe7c9ihUVeam","P9fYcrNhVgKi"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}