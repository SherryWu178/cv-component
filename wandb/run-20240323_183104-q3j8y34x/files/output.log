predicted tensor([[0.3383, 0.3868, 0.2748],
        [0.2938, 0.4334, 0.2729],
        [0.2955, 0.4061, 0.2984],
        [0.3131, 0.3873, 0.2996],
        [0.3069, 0.4144, 0.2787],
        [0.3028, 0.4146, 0.2826],
        [0.2892, 0.4090, 0.3018],
        [0.3406, 0.3895, 0.2699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
Train Epoch: 0 [0 (0%)]	Loss: 1.108097	Accuracy: 0.125000
predicted tensor([[0.8634, 0.0614, 0.0752],
        [0.8584, 0.0635, 0.0781],
        [0.8943, 0.0464, 0.0593],
        [0.8450, 0.0699, 0.0851],
        [0.8776, 0.0551, 0.0674],
        [0.8744, 0.0567, 0.0689],
        [0.8748, 0.0586, 0.0666],
        [0.8564, 0.0632, 0.0805]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]], device='cuda:0')
predicted tensor([[0.8389, 0.0411, 0.1200],
        [0.8858, 0.0294, 0.0848],
        [0.8484, 0.0403, 0.1114],
        [0.8435, 0.0408, 0.1157],
        [0.8476, 0.0374, 0.1150],
        [0.8664, 0.0375, 0.0961],
        [0.8366, 0.0441, 0.1193],
        [0.8406, 0.0455, 0.1139]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[0.8616, 0.0318, 0.1066],
        [0.8973, 0.0252, 0.0775],
        [0.8263, 0.0406, 0.1331],
        [0.8554, 0.0341, 0.1105],
        [0.8451, 0.0361, 0.1188],
        [0.8361, 0.0389, 0.1250],
        [0.8248, 0.0381, 0.1371],
        [0.8295, 0.0393, 0.1312]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[0.9382, 0.0194, 0.0424],
        [0.9465, 0.0172, 0.0363],
        [0.9455, 0.0171, 0.0374],
        [0.9300, 0.0204, 0.0497],
        [0.9358, 0.0207, 0.0435],
        [0.9453, 0.0170, 0.0377],
        [0.9517, 0.0146, 0.0337],
        [0.9325, 0.0218, 0.0457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[0.9768, 0.0097, 0.0135],
        [0.9766, 0.0096, 0.0138],
        [0.9764, 0.0093, 0.0143],
        [0.9739, 0.0109, 0.0152],
        [0.9841, 0.0069, 0.0090],
        [0.9752, 0.0088, 0.0159],
        [0.9759, 0.0091, 0.0151],
        [0.9820, 0.0082, 0.0098]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[0.9926, 0.0036, 0.0038],
        [0.9894, 0.0054, 0.0052],
        [0.9926, 0.0037, 0.0037],
        [0.9918, 0.0040, 0.0042],
        [0.9892, 0.0041, 0.0067],
        [0.9905, 0.0050, 0.0045],
        [0.9939, 0.0031, 0.0029],
        [0.9897, 0.0046, 0.0056]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[0.9972, 0.0016, 0.0012],
        [0.9952, 0.0024, 0.0023],
        [0.9949, 0.0026, 0.0025],
        [0.9962, 0.0021, 0.0017],
        [0.9970, 0.0017, 0.0012],
        [0.9961, 0.0022, 0.0017],
        [0.9951, 0.0026, 0.0023],
        [0.9952, 0.0028, 0.0020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9824e-01, 1.1153e-03, 6.4343e-04],
        [9.9702e-01, 1.6484e-03, 1.3296e-03],
        [9.9827e-01, 1.0939e-03, 6.3372e-04],
        [9.9820e-01, 1.1322e-03, 6.6582e-04],
        [9.9798e-01, 1.2884e-03, 7.3011e-04],
        [9.9843e-01, 9.7428e-04, 5.9214e-04],
        [9.9761e-01, 1.6075e-03, 7.7924e-04],
        [9.9664e-01, 1.9655e-03, 1.3918e-03]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.]], device='cuda:0')
Train Epoch: 0 [8 (26%)]	Loss: 0.801807	Accuracy: 0.750000
predicted tensor([[9.9855e-01, 9.5780e-04, 4.8952e-04],
        [9.9868e-01, 9.3924e-04, 3.8335e-04],
        [9.9923e-01, 5.1269e-04, 2.5616e-04],
        [9.9851e-01, 9.2925e-04, 5.6229e-04],
        [9.9912e-01, 6.2202e-04, 2.6077e-04],
        [9.9865e-01, 9.1181e-04, 4.3953e-04],
        [9.9853e-01, 9.4488e-04, 5.2972e-04],
        [9.9880e-01, 8.1259e-04, 3.8972e-04]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9935e-01, 4.8672e-04, 1.6249e-04],
        [9.9939e-01, 4.6667e-04, 1.4592e-04],
        [9.9942e-01, 4.1204e-04, 1.7233e-04],
        [9.9918e-01, 6.1945e-04, 2.0382e-04],
        [9.9929e-01, 5.1356e-04, 1.9930e-04],
        [9.9925e-01, 5.3716e-04, 2.1108e-04],
        [9.9890e-01, 7.2357e-04, 3.7188e-04],
        [9.9925e-01, 4.6831e-04, 2.8090e-04]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.]], device='cuda:0')
predicted tensor([[9.9963e-01, 2.9015e-04, 7.9642e-05],
        [9.9969e-01, 2.3213e-04, 7.4793e-05],
        [9.9968e-01, 2.3568e-04, 8.1266e-05],
        [9.9910e-01, 6.2073e-04, 2.8293e-04],
        [9.9943e-01, 3.8820e-04, 1.8558e-04],
        [9.9944e-01, 4.3216e-04, 1.2906e-04],
        [9.9962e-01, 3.0120e-04, 8.2808e-05],
        [9.9941e-01, 4.5380e-04, 1.3983e-04]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [0., 1., 0.],
        [0., 1., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9980e-01, 1.6178e-04, 3.5580e-05],
        [9.9971e-01, 2.2299e-04, 6.5536e-05],
        [9.9962e-01, 3.2131e-04, 6.3658e-05],
        [9.9977e-01, 1.8306e-04, 5.0020e-05],
        [9.9955e-01, 2.9879e-04, 1.5353e-04],
        [9.9951e-01, 3.3671e-04, 1.4930e-04],
        [9.9976e-01, 1.9630e-04, 4.7132e-05],
        [9.9963e-01, 2.9526e-04, 7.1890e-05]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9979e-01, 1.7684e-04, 3.3741e-05],
        [9.9972e-01, 2.1328e-04, 6.9446e-05],
        [9.9978e-01, 1.7232e-04, 4.3556e-05],
        [9.9978e-01, 1.8398e-04, 4.0097e-05],
        [9.9981e-01, 1.5755e-04, 3.1086e-05],
        [9.9965e-01, 2.5510e-04, 9.7026e-05],
        [9.9984e-01, 1.3229e-04, 3.2348e-05],
        [9.9983e-01, 1.3602e-04, 3.4289e-05]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9981e-01, 1.6535e-04, 2.9349e-05],
        [9.9989e-01, 8.8491e-05, 1.7895e-05],
        [9.9982e-01, 1.4897e-04, 3.5478e-05],
        [9.9981e-01, 1.4691e-04, 4.4800e-05],
        [9.9984e-01, 1.2825e-04, 3.0581e-05],
        [9.9984e-01, 1.2663e-04, 3.0877e-05],
        [9.9988e-01, 1.0366e-04, 1.7317e-05],
        [9.9983e-01, 1.3753e-04, 3.1710e-05]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9986e-01, 1.1010e-04, 2.6470e-05],
        [9.9989e-01, 9.0026e-05, 1.5755e-05],
        [9.9989e-01, 8.7927e-05, 2.2132e-05],
        [9.9989e-01, 9.7435e-05, 1.6836e-05],
        [9.9990e-01, 8.2257e-05, 1.4993e-05],
        [9.9989e-01, 9.3731e-05, 2.0955e-05],
        [9.9989e-01, 9.2200e-05, 1.9682e-05],
        [9.9988e-01, 9.7686e-05, 1.8739e-05]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9989e-01, 9.0938e-05, 2.2688e-05],
        [9.9988e-01, 9.4676e-05, 2.2968e-05],
        [9.9988e-01, 9.6388e-05, 1.8553e-05],
        [9.9995e-01, 4.6411e-05, 6.7876e-06],
        [9.9992e-01, 6.7302e-05, 1.5370e-05],
        [9.9994e-01, 5.2607e-05, 6.7978e-06],
        [9.9992e-01, 6.3607e-05, 1.4930e-05],
        [9.9990e-01, 8.6145e-05, 1.3421e-05]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
Train Epoch: 0 [16 (52%)]	Loss: 1.051443	Accuracy: 0.500000
predicted tensor([[9.9993e-01, 5.4701e-05, 1.6911e-05],
        [9.9997e-01, 2.3652e-05, 3.7460e-06],
        [9.9996e-01, 3.1168e-05, 4.3014e-06],
        [9.9993e-01, 6.4928e-05, 9.1135e-06],
        [9.9994e-01, 5.1760e-05, 1.2932e-05],
        [9.9994e-01, 5.1836e-05, 9.7678e-06],
        [9.9994e-01, 5.4940e-05, 8.0073e-06],
        [9.9994e-01, 5.3721e-05, 7.4781e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9996e-01, 3.2457e-05, 5.5472e-06],
        [9.9995e-01, 4.4787e-05, 5.6071e-06],
        [9.9996e-01, 3.5196e-05, 6.4353e-06],
        [9.9995e-01, 4.6741e-05, 7.6460e-06],
        [9.9997e-01, 2.9585e-05, 4.8552e-06],
        [9.9995e-01, 4.2128e-05, 6.8973e-06],
        [9.9996e-01, 3.5093e-05, 6.3616e-06],
        [9.9996e-01, 3.1710e-05, 5.5569e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9997e-01, 2.6738e-05, 3.9514e-06],
        [9.9995e-01, 4.0413e-05, 6.0499e-06],
        [9.9998e-01, 2.0262e-05, 2.1372e-06],
        [9.9997e-01, 2.3376e-05, 4.3547e-06],
        [9.9996e-01, 3.5077e-05, 9.1238e-06],
        [9.9996e-01, 3.1227e-05, 4.1622e-06],
        [9.9996e-01, 3.1119e-05, 4.7086e-06],
        [9.9996e-01, 3.7073e-05, 5.6918e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9998e-01, 1.7513e-05, 2.7732e-06],
        [9.9997e-01, 2.4586e-05, 2.8695e-06],
        [9.9998e-01, 2.1636e-05, 2.8272e-06],
        [9.9997e-01, 2.5535e-05, 4.7071e-06],
        [9.9996e-01, 2.9394e-05, 5.9043e-06],
        [9.9995e-01, 3.9149e-05, 7.0246e-06],
        [9.9998e-01, 1.8967e-05, 3.1612e-06],
        [9.9996e-01, 3.2252e-05, 3.0866e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9997e-01, 2.7002e-05, 2.7560e-06],
        [9.9997e-01, 2.6747e-05, 2.7234e-06],
        [9.9997e-01, 2.2270e-05, 4.6676e-06],
        [9.9999e-01, 1.1261e-05, 1.8064e-06],
        [9.9997e-01, 2.8890e-05, 4.0738e-06],
        [9.9998e-01, 1.5490e-05, 1.9334e-06],
        [9.9996e-01, 3.2243e-05, 7.2698e-06],
        [9.9998e-01, 2.1063e-05, 2.8871e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9998e-01, 1.9118e-05, 2.4961e-06],
        [9.9998e-01, 1.7536e-05, 2.1019e-06],
        [9.9998e-01, 1.6699e-05, 2.6239e-06],
        [9.9997e-01, 2.6711e-05, 4.4845e-06],
        [9.9997e-01, 2.2498e-05, 2.4688e-06],
        [9.9998e-01, 1.6269e-05, 1.8299e-06],
        [9.9997e-01, 2.0419e-05, 5.0990e-06],
        [9.9998e-01, 1.6313e-05, 1.8339e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9998e-01, 1.8761e-05, 2.6361e-06],
        [9.9997e-01, 2.4449e-05, 3.3136e-06],
        [9.9997e-01, 2.5725e-05, 3.2769e-06],
        [9.9999e-01, 9.5896e-06, 1.0047e-06],
        [9.9997e-01, 2.3433e-05, 4.8685e-06],
        [9.9998e-01, 1.5121e-05, 1.5839e-06],
        [9.9999e-01, 7.6992e-06, 8.3640e-07],
        [9.9998e-01, 1.8813e-05, 3.4154e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.]], device='cuda:0')
Train Epoch: 0 [24 (77%)]	Loss: 1.051443	Accuracy: 0.500000
predicted tensor([[9.9998e-01, 1.9035e-05, 4.2869e-06],
        [9.9999e-01, 1.2924e-05, 1.4254e-06],
        [9.9998e-01, 1.4842e-05, 1.5958e-06],
        [9.9998e-01, 1.9177e-05, 3.0689e-06],
        [9.9998e-01, 1.6722e-05, 1.9877e-06],
        [9.9999e-01, 1.1338e-05, 1.3276e-06],
        [9.9999e-01, 1.2027e-05, 1.3162e-06],
        [9.9998e-01, 1.6098e-05, 1.9268e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.5037e-06, 5.5318e-07],
        [9.9998e-01, 1.4241e-05, 1.8278e-06],
        [9.9998e-01, 2.0292e-05, 3.3417e-06],
        [9.9999e-01, 1.3583e-05, 1.2017e-06],
        [9.9998e-01, 2.1204e-05, 3.0349e-06],
        [9.9997e-01, 2.1696e-05, 3.8250e-06],
        [9.9999e-01, 1.1209e-05, 1.9557e-06],
        [9.9999e-01, 9.7095e-06, 1.0427e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.5477e-06, 7.6193e-07],
        [9.9999e-01, 9.2866e-06, 1.3119e-06],
        [9.9999e-01, 1.0025e-05, 9.0763e-07],
        [9.9998e-01, 1.3657e-05, 2.2312e-06],
        [9.9999e-01, 9.5951e-06, 1.4980e-06],
        [9.9998e-01, 1.8081e-05, 2.4874e-06],
        [9.9998e-01, 1.8080e-05, 1.4218e-06],
        [9.9998e-01, 2.1267e-05, 3.5948e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]], device='cuda:0')
predicted tensor([[9.9999e-01, 9.2281e-06, 1.0460e-06],
        [9.9998e-01, 1.8293e-05, 2.5757e-06],
        [9.9999e-01, 8.7043e-06, 9.1024e-07],
        [9.9999e-01, 8.9935e-06, 1.1031e-06],
        [9.9998e-01, 1.4820e-05, 1.8259e-06],
        [9.9999e-01, 6.6529e-06, 6.4852e-07],
        [9.9998e-01, 1.3579e-05, 1.7496e-06],
        [9.9998e-01, 1.3425e-05, 1.8846e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.0091e-06, 4.5884e-07],
        [9.9997e-01, 2.1409e-05, 4.5162e-06],
        [9.9998e-01, 1.4643e-05, 2.1172e-06],
        [9.9998e-01, 1.5456e-05, 1.7700e-06],
        [9.9999e-01, 1.0694e-05, 1.3657e-06],
        [9.9999e-01, 7.4498e-06, 7.4863e-07],
        [9.9999e-01, 6.0144e-06, 6.4162e-07],
        [9.9998e-01, 1.5342e-05, 1.4114e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 8.6401e-06, 7.8201e-07],
        [9.9999e-01, 8.2662e-06, 7.7367e-07],
        [9.9999e-01, 1.0515e-05, 1.8637e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.]], device='cuda:0')
iter
(243, 3) (243, 3) (243, 3)
(243,) (243,)
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
<function compute_ap at 0x7b0a6fe936d0>
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.] [0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.] [0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1.] [0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21]
[[147   0   0]
 [ 45   0   0]
 [ 51   0   0]]
[0.41 0.1  0.12]
map:  0.20928173838262906
predicted tensor([[9.9999e-01, 1.0032e-05, 1.0164e-06],
        [9.9998e-01, 1.4327e-05, 1.2632e-06],
        [9.9999e-01, 5.2552e-06, 7.0221e-07],
        [9.9999e-01, 1.0572e-05, 1.2119e-06],
        [9.9999e-01, 1.1127e-05, 1.1558e-06],
        [9.9999e-01, 9.2706e-06, 1.1528e-06],
        [9.9998e-01, 1.2573e-05, 2.6113e-06],
        [9.9999e-01, 6.3017e-06, 5.3730e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 1.1329e-05, 1.3836e-06],
        [9.9999e-01, 1.0820e-05, 1.8168e-06],
        [9.9999e-01, 8.9783e-06, 5.1292e-07],
        [9.9999e-01, 8.5945e-06, 1.3131e-06],
        [9.9999e-01, 5.1916e-06, 4.5902e-07],
        [9.9999e-01, 6.4294e-06, 5.4700e-07],
        [9.9999e-01, 8.9970e-06, 1.3239e-06],
        [9.9999e-01, 9.5684e-06, 1.2366e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [0., 0., 1.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.]], device='cuda:0')
Train Epoch: 1 [32 (3%)]	Loss: 1.301441	Accuracy: 0.250000
predicted tensor([[9.9999e-01, 8.6680e-06, 1.2542e-06],
        [9.9999e-01, 6.5503e-06, 5.4472e-07],
        [9.9999e-01, 7.9946e-06, 7.6290e-07],
        [9.9999e-01, 5.1408e-06, 4.5410e-07],
        [9.9998e-01, 1.3674e-05, 1.9650e-06],
        [9.9999e-01, 8.9418e-06, 1.5119e-06],
        [9.9999e-01, 6.7401e-06, 6.3141e-07],
        [9.9999e-01, 8.4570e-06, 7.7273e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.4837e-06, 6.1094e-07],
        [9.9999e-01, 8.0405e-06, 1.2075e-06],
        [9.9998e-01, 1.3252e-05, 1.9476e-06],
        [9.9999e-01, 1.0929e-05, 1.7089e-06],
        [1.0000e+00, 4.4177e-06, 3.5853e-07],
        [9.9999e-01, 4.8477e-06, 3.3088e-07],
        [9.9998e-01, 1.6097e-05, 2.3695e-06],
        [9.9999e-01, 5.0800e-06, 4.6309e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 1.0748e-05, 1.6797e-06],
        [9.9999e-01, 8.2717e-06, 8.1578e-07],
        [9.9999e-01, 4.8123e-06, 6.5048e-07],
        [9.9999e-01, 1.1628e-05, 1.5114e-06],
        [9.9999e-01, 4.6272e-06, 3.2480e-07],
        [9.9999e-01, 4.6747e-06, 3.3645e-07],
        [9.9999e-01, 1.1156e-05, 1.6678e-06],
        [9.9999e-01, 9.5960e-06, 8.8232e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.6863e-06, 6.6998e-07],
        [9.9999e-01, 5.4555e-06, 5.2470e-07],
        [9.9999e-01, 6.7836e-06, 6.4849e-07],
        [9.9999e-01, 8.3946e-06, 5.5355e-07],
        [9.9999e-01, 1.1963e-05, 1.7251e-06],
        [9.9999e-01, 8.5614e-06, 1.3973e-06],
        [9.9999e-01, 8.0642e-06, 9.6526e-07],
        [1.0000e+00, 3.9348e-06, 3.5512e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.6631e-06, 7.5005e-07],
        [9.9999e-01, 8.8721e-06, 7.5324e-07],
        [9.9999e-01, 9.3486e-06, 1.2020e-06],
        [9.9999e-01, 7.3878e-06, 7.2610e-07],
        [9.9999e-01, 4.5601e-06, 4.9007e-07],
        [9.9999e-01, 6.9963e-06, 7.4389e-07],
        [9.9999e-01, 4.9021e-06, 4.9890e-07],
        [9.9999e-01, 1.0550e-05, 1.1058e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.1622e-06, 9.1408e-07],
        [9.9999e-01, 1.0338e-05, 2.0312e-06],
        [9.9999e-01, 4.7995e-06, 4.0545e-07],
        [9.9999e-01, 5.0471e-06, 4.2094e-07],
        [1.0000e+00, 4.5005e-06, 3.5183e-07],
        [9.9999e-01, 9.3182e-06, 7.3182e-07],
        [9.9999e-01, 6.9167e-06, 7.6812e-07],
        [9.9999e-01, 8.3831e-06, 1.0254e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.3398e-06, 7.2046e-07],
        [9.9999e-01, 7.6449e-06, 7.1374e-07],
        [1.0000e+00, 3.7923e-06, 3.1578e-07],
        [9.9999e-01, 7.3141e-06, 9.5798e-07],
        [9.9999e-01, 8.5430e-06, 9.0349e-07],
        [9.9999e-01, 5.8561e-06, 4.9966e-07],
        [9.9999e-01, 7.9299e-06, 1.1651e-06],
        [9.9999e-01, 4.7246e-06, 4.7432e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 8.6790e-06, 6.9862e-07],
        [9.9999e-01, 9.0333e-06, 1.0410e-06],
        [9.9998e-01, 1.2823e-05, 2.9520e-06],
        [9.9999e-01, 4.9180e-06, 4.6248e-07],
        [9.9999e-01, 7.0035e-06, 6.4354e-07],
        [9.9999e-01, 5.1734e-06, 4.7317e-07],
        [1.0000e+00, 2.7049e-06, 2.5966e-07],
        [1.0000e+00, 4.3281e-06, 3.8587e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
Train Epoch: 1 [40 (29%)]	Loss: 0.801445	Accuracy: 0.750000
predicted tensor([[9.9999e-01, 5.4640e-06, 5.1693e-07],
        [9.9999e-01, 6.0931e-06, 1.1038e-06],
        [9.9999e-01, 1.0149e-05, 1.4015e-06],
        [1.0000e+00, 4.4073e-06, 4.8328e-07],
        [9.9999e-01, 7.4281e-06, 6.2438e-07],
        [9.9999e-01, 6.9465e-06, 6.2904e-07],
        [9.9999e-01, 5.4964e-06, 3.8945e-07],
        [9.9999e-01, 6.1472e-06, 5.5205e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 4.8985e-06, 5.5843e-07],
        [9.9999e-01, 7.0446e-06, 7.2766e-07],
        [1.0000e+00, 3.7112e-06, 2.9165e-07],
        [9.9999e-01, 1.1677e-05, 1.5036e-06],
        [9.9999e-01, 5.7308e-06, 6.4138e-07],
        [1.0000e+00, 3.5028e-06, 3.1683e-07],
        [9.9999e-01, 6.9587e-06, 9.7449e-07],
        [9.9999e-01, 7.7253e-06, 4.6582e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.8486e-06, 8.2002e-07],
        [9.9999e-01, 5.9599e-06, 6.9930e-07],
        [9.9999e-01, 7.7704e-06, 7.9458e-07],
        [9.9999e-01, 7.7609e-06, 1.0564e-06],
        [1.0000e+00, 4.1481e-06, 3.3594e-07],
        [9.9999e-01, 6.3116e-06, 5.4968e-07],
        [1.0000e+00, 4.4916e-06, 3.7050e-07],
        [1.0000e+00, 4.0063e-06, 3.9966e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.4074e-06, 4.1493e-07],
        [9.9999e-01, 6.7785e-06, 8.8917e-07],
        [9.9999e-01, 6.5409e-06, 6.3838e-07],
        [9.9999e-01, 6.2621e-06, 5.0766e-07],
        [1.0000e+00, 2.7842e-06, 2.8828e-07],
        [9.9999e-01, 6.6566e-06, 6.2563e-07],
        [9.9999e-01, 6.8944e-06, 9.8167e-07],
        [9.9999e-01, 5.5037e-06, 6.9527e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 4.5730e-06, 3.5734e-07],
        [1.0000e+00, 3.7018e-06, 3.7380e-07],
        [9.9999e-01, 6.5158e-06, 9.7660e-07],
        [9.9999e-01, 5.5606e-06, 5.5333e-07],
        [9.9999e-01, 5.2562e-06, 8.4409e-07],
        [9.9999e-01, 7.3799e-06, 4.8898e-07],
        [9.9999e-01, 6.7990e-06, 5.0828e-07],
        [9.9999e-01, 6.9719e-06, 7.0674e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 8.0801e-06, 1.3826e-06],
        [9.9999e-01, 6.0290e-06, 5.3632e-07],
        [1.0000e+00, 4.0240e-06, 3.9954e-07],
        [9.9999e-01, 6.8004e-06, 4.6245e-07],
        [9.9999e-01, 8.3804e-06, 7.3290e-07],
        [9.9999e-01, 5.5051e-06, 7.1644e-07],
        [1.0000e+00, 3.3321e-06, 3.0359e-07],
        [9.9999e-01, 5.3150e-06, 5.1211e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.1632e-06, 4.3606e-07],
        [9.9999e-01, 7.6769e-06, 1.6445e-06],
        [9.9999e-01, 7.4242e-06, 1.1458e-06],
        [9.9999e-01, 4.9640e-06, 3.5072e-07],
        [1.0000e+00, 2.5614e-06, 1.7026e-07],
        [9.9999e-01, 5.9261e-06, 4.6924e-07],
        [1.0000e+00, 4.4093e-06, 3.4495e-07],
        [9.9999e-01, 6.9260e-06, 7.8225e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.2569e-06, 9.0932e-07],
        [9.9999e-01, 1.0966e-05, 1.3511e-06],
        [1.0000e+00, 4.2077e-06, 3.5783e-07],
        [9.9999e-01, 4.9256e-06, 4.4200e-07],
        [1.0000e+00, 3.2022e-06, 2.5813e-07],
        [9.9999e-01, 4.7516e-06, 5.8704e-07],
        [9.9999e-01, 5.1176e-06, 4.4551e-07],
        [1.0000e+00, 4.4412e-06, 3.9154e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.9335e-06, 8.9420e-07],
        [1.0000e+00, 3.8441e-06, 3.6307e-07],
        [9.9999e-01, 5.1933e-06, 7.6059e-07],
        [9.9999e-01, 8.2452e-06, 5.6013e-07],
        [1.0000e+00, 3.0471e-06, 3.2808e-07],
        [9.9999e-01, 8.1403e-06, 1.2356e-06],
        [9.9999e-01, 4.8023e-06, 3.8418e-07],
        [1.0000e+00, 3.1855e-06, 2.1813e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.8238e-06, 7.9068e-07],
        [1.0000e+00, 3.8430e-06, 3.3473e-07],
        [1.0000e+00, 3.1618e-06, 2.4239e-07],
        [1.0000e+00, 3.8046e-06, 3.0946e-07],
        [9.9999e-01, 5.8482e-06, 9.2892e-07],
        [9.9999e-01, 8.0935e-06, 1.3333e-06],
        [1.0000e+00, 3.1478e-06, 2.8718e-07],
        [9.9999e-01, 6.0808e-06, 5.0360e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 2.5095e-06, 2.4028e-07],
        [9.9999e-01, 6.6020e-06, 5.4351e-07],
        [1.0000e+00, 3.8860e-06, 3.6148e-07],
        [9.9999e-01, 6.4123e-06, 1.2044e-06],
        [9.9999e-01, 6.3168e-06, 4.8790e-07],
        [9.9999e-01, 6.3833e-06, 4.8253e-07],
        [9.9999e-01, 4.9464e-06, 5.7162e-07],
        [9.9999e-01, 4.8856e-06, 6.2461e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.0623e-06, 5.2160e-07],
        [9.9999e-01, 5.0545e-06, 4.4761e-07],
        [9.9999e-01, 5.7906e-06, 5.5639e-07],
        [1.0000e+00, 3.5687e-06, 3.9718e-07],
        [9.9999e-01, 9.2657e-06, 9.0432e-07],
        [1.0000e+00, 3.5081e-06, 3.3510e-07],
        [1.0000e+00, 3.9538e-06, 4.0352e-07],
        [9.9999e-01, 4.5773e-06, 4.4658e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.0841e-06, 9.6147e-07],
        [9.9999e-01, 6.0715e-06, 5.1855e-07],
        [1.0000e+00, 4.4276e-06, 4.3291e-07],
        [9.9999e-01, 4.8515e-06, 3.9818e-07],
        [9.9999e-01, 5.0127e-06, 5.1010e-07],
        [9.9999e-01, 4.6136e-06, 4.7955e-07],
        [9.9999e-01, 5.6979e-06, 5.6814e-07],
        [1.0000e+00, 4.0470e-06, 3.6108e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.0609e-06, 4.6979e-07],
        [1.0000e+00, 2.6617e-06, 2.1521e-07],
        [9.9999e-01, 5.3408e-06, 6.3191e-07],
        [1.0000e+00, 3.1530e-06, 2.7448e-07],
        [9.9999e-01, 4.9895e-06, 5.2662e-07],
        [9.9999e-01, 5.6707e-06, 4.9428e-07],
        [9.9999e-01, 7.1519e-06, 1.2408e-06],
        [9.9999e-01, 6.7271e-06, 5.0253e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 9.3621e-06, 1.4041e-06],
        [1.0000e+00, 3.5712e-06, 2.5760e-07],
        [9.9999e-01, 5.2150e-06, 3.8943e-07],
        [1.0000e+00, 3.3533e-06, 2.7223e-07],
        [9.9999e-01, 5.4055e-06, 7.2776e-07],
        [9.9999e-01, 5.1167e-06, 4.8483e-07],
        [9.9999e-01, 7.1460e-06, 9.5983e-07],
        [1.0000e+00, 2.9429e-06, 2.0810e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
Train Epoch: 1 [56 (81%)]	Loss: 0.926445	Accuracy: 0.625000
predicted tensor([[9.9999e-01, 6.5533e-06, 1.0554e-06],
        [1.0000e+00, 2.1180e-06, 1.6072e-07],
        [9.9999e-01, 5.4992e-06, 5.5753e-07],
        [1.0000e+00, 4.0158e-06, 2.7618e-07],
        [9.9999e-01, 5.0522e-06, 3.1910e-07],
        [9.9999e-01, 7.6133e-06, 7.6068e-07],
        [9.9999e-01, 4.9660e-06, 5.1845e-07],
        [9.9999e-01, 5.7924e-06, 8.3165e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [0., 0., 1.]], device='cuda:0')
predicted tensor([[1.0000e+00, 3.7069e-06, 3.8086e-07],
        [9.9999e-01, 5.5966e-06, 9.5256e-07],
        [9.9999e-01, 4.7571e-06, 4.8141e-07],
        [9.9999e-01, 8.9431e-06, 1.3248e-06],
        [1.0000e+00, 4.1732e-06, 3.2343e-07],
        [9.9999e-01, 7.5079e-06, 5.6934e-07],
        [9.9999e-01, 7.1179e-06, 5.1414e-07],
        [1.0000e+00, 2.0570e-06, 1.4569e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.6303e-06, 7.9856e-07],
        [9.9999e-01, 4.9862e-06, 4.6469e-07],
        [1.0000e+00, 3.2360e-06, 2.7191e-07],
        [1.0000e+00, 4.4631e-06, 4.1888e-07],
        [1.0000e+00, 4.1604e-06, 4.1775e-07],
        [9.9999e-01, 5.3879e-06, 7.5921e-07],
        [9.9999e-01, 4.9553e-06, 4.9745e-07],
        [9.9999e-01, 7.2394e-06, 5.0974e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 4.3682e-06, 3.1877e-07],
        [9.9999e-01, 6.1778e-06, 4.0906e-07],
        [9.9999e-01, 5.1657e-06, 7.7450e-07],
        [1.0000e+00, 2.2781e-06, 1.5770e-07],
        [1.0000e+00, 2.4046e-06, 1.9019e-07],
        [9.9999e-01, 9.5004e-06, 1.3611e-06],
        [9.9999e-01, 7.8790e-06, 1.2142e-06],
        [9.9999e-01, 6.3411e-06, 6.0756e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 4.9608e-06, 3.9991e-07],
        [1.0000e+00, 3.0564e-06, 2.7894e-07],
        [9.9999e-01, 6.3326e-06, 7.7650e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
iter
(243, 3) (243, 3) (243, 3)
(243,) (243,)
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
<function compute_ap at 0x7b0a6fe936d0>
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.] [0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.] [0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1.] [0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21]
[[147   0   0]
 [ 45   0   0]
 [ 51   0   0]]
[0.4  0.1  0.12]
map:  0.2067978619858528
predicted tensor([[9.9999e-01, 6.0208e-06, 8.7873e-07],
        [1.0000e+00, 2.7658e-06, 2.7164e-07],
        [1.0000e+00, 3.1897e-06, 3.1171e-07],
        [9.9999e-01, 1.0006e-05, 1.5837e-06],
        [1.0000e+00, 3.1229e-06, 2.6595e-07],
        [9.9999e-01, 6.3710e-06, 5.4727e-07],
        [9.9999e-01, 4.8087e-06, 4.4167e-07],
        [9.9999e-01, 6.0922e-06, 3.9465e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.2009e-06, 4.5914e-07],
        [9.9999e-01, 6.0957e-06, 9.4379e-07],
        [1.0000e+00, 4.0989e-06, 2.9865e-07],
        [1.0000e+00, 2.1594e-06, 1.6425e-07],
        [9.9999e-01, 5.0835e-06, 5.6079e-07],
        [9.9999e-01, 5.3305e-06, 4.5285e-07],
        [9.9999e-01, 7.3538e-06, 7.6491e-07],
        [9.9999e-01, 5.2195e-06, 6.1360e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.4426e-06, 9.3889e-07],
        [1.0000e+00, 4.5276e-06, 2.8827e-07],
        [9.9999e-01, 6.6261e-06, 5.5411e-07],
        [9.9999e-01, 6.3525e-06, 8.7096e-07],
        [1.0000e+00, 3.7155e-06, 3.4245e-07],
        [9.9999e-01, 5.4750e-06, 5.7554e-07],
        [1.0000e+00, 3.2170e-06, 3.3641e-07],
        [9.9999e-01, 6.1265e-06, 4.8217e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [0., 1., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
Train Epoch: 2 [64 (6%)]	Loss: 1.301441	Accuracy: 0.250000
predicted tensor([[1.0000e+00, 4.2246e-06, 3.2186e-07],
        [9.9999e-01, 6.7401e-06, 1.1419e-06],
        [9.9999e-01, 6.8031e-06, 3.7209e-07],
        [1.0000e+00, 3.2497e-06, 2.6140e-07],
        [1.0000e+00, 2.2921e-06, 2.0366e-07],
        [9.9999e-01, 4.4973e-06, 4.7891e-07],
        [9.9999e-01, 6.5424e-06, 8.1611e-07],
        [9.9999e-01, 8.2872e-06, 1.0542e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 4.4831e-06, 3.9041e-07],
        [1.0000e+00, 4.3168e-06, 3.3275e-07],
        [1.0000e+00, 1.7353e-06, 1.0922e-07],
        [9.9999e-01, 5.9135e-06, 7.0735e-07],
        [9.9999e-01, 8.5642e-06, 1.1083e-06],
        [9.9999e-01, 6.5388e-06, 6.2530e-07],
        [9.9999e-01, 5.3226e-06, 4.8405e-07],
        [9.9999e-01, 4.9582e-06, 6.2051e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.]], device='cuda:0')
predicted tensor([[1.0000e+00, 3.4834e-06, 2.9650e-07],
        [9.9999e-01, 7.3764e-06, 1.0956e-06],
        [9.9999e-01, 4.9695e-06, 4.7415e-07],
        [1.0000e+00, 3.2168e-06, 2.5014e-07],
        [1.0000e+00, 3.8176e-06, 2.6552e-07],
        [9.9999e-01, 4.8851e-06, 5.6945e-07],
        [9.9999e-01, 6.7477e-06, 8.2268e-07],
        [9.9999e-01, 7.4288e-06, 5.8970e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 4.3818e-06, 4.1066e-07],
        [1.0000e+00, 4.5026e-06, 3.7805e-07],
        [9.9999e-01, 8.3332e-06, 1.6703e-06],
        [1.0000e+00, 1.9378e-06, 1.3703e-07],
        [9.9999e-01, 8.5486e-06, 5.3709e-07],
        [9.9999e-01, 4.8054e-06, 4.3705e-07],
        [1.0000e+00, 4.1069e-06, 4.1286e-07],
        [9.9999e-01, 6.4247e-06, 7.6479e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.7774e-06, 7.2541e-07],
        [9.9999e-01, 6.9621e-06, 7.3385e-07],
        [9.9999e-01, 6.9427e-06, 6.7072e-07],
        [9.9999e-01, 5.4544e-06, 4.0484e-07],
        [1.0000e+00, 2.9639e-06, 3.7544e-07],
        [9.9999e-01, 5.5880e-06, 5.4076e-07],
        [9.9999e-01, 5.2918e-06, 4.7977e-07],
        [1.0000e+00, 3.1137e-06, 2.4182e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.4972e-06, 5.3106e-07],
        [9.9999e-01, 5.2972e-06, 5.5609e-07],
        [1.0000e+00, 2.7654e-06, 2.3511e-07],
        [1.0000e+00, 3.9669e-06, 3.4635e-07],
        [1.0000e+00, 3.7407e-06, 3.2105e-07],
        [9.9999e-01, 5.6899e-06, 5.2785e-07],
        [9.9999e-01, 6.7665e-06, 6.5827e-07],
        [9.9999e-01, 7.7049e-06, 1.1472e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 3.0025e-06, 2.3099e-07],
        [9.9999e-01, 6.2329e-06, 5.8293e-07],
        [9.9999e-01, 5.7073e-06, 5.2115e-07],
        [1.0000e+00, 3.0941e-06, 2.0438e-07],
        [9.9999e-01, 5.9913e-06, 5.1345e-07],
        [9.9999e-01, 5.7146e-06, 4.8520e-07],
        [9.9999e-01, 9.3451e-06, 1.8212e-06],
        [9.9999e-01, 4.7585e-06, 5.6531e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.9920e-06, 3.9949e-07],
        [9.9999e-01, 4.6005e-06, 7.0527e-07],
        [1.0000e+00, 4.0238e-06, 3.6070e-07],
        [1.0000e+00, 3.1550e-06, 2.5537e-07],
        [9.9999e-01, 7.3516e-06, 1.3531e-06],
        [9.9999e-01, 6.0739e-06, 9.4224e-07],
        [1.0000e+00, 3.3040e-06, 2.4100e-07],
        [9.9999e-01, 6.9386e-06, 4.9209e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
Train Epoch: 2 [72 (32%)]	Loss: 1.176442	Accuracy: 0.375000
predicted tensor([[1.0000e+00, 4.0893e-06, 4.1762e-07],
        [9.9999e-01, 6.1302e-06, 1.1477e-06],
        [9.9999e-01, 7.8010e-06, 7.2394e-07],
        [1.0000e+00, 2.7595e-06, 2.2948e-07],
        [1.0000e+00, 3.6716e-06, 3.4649e-07],
        [9.9999e-01, 7.1666e-06, 4.2627e-07],
        [1.0000e+00, 3.0054e-06, 3.3603e-07],
        [9.9999e-01, 6.3449e-06, 5.8980e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 3.0295e-06, 3.0256e-07],
        [1.0000e+00, 4.2155e-06, 4.4411e-07],
        [9.9999e-01, 7.2844e-06, 7.7767e-07],
        [9.9999e-01, 6.3289e-06, 9.0482e-07],
        [1.0000e+00, 1.6627e-06, 1.2703e-07],
        [9.9999e-01, 7.5851e-06, 1.0083e-06],
        [9.9999e-01, 5.9327e-06, 4.1235e-07],
        [9.9999e-01, 5.2121e-06, 5.1937e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 8.4680e-06, 9.5919e-07],
        [9.9999e-01, 7.0849e-06, 7.3595e-07],
        [9.9999e-01, 5.4537e-06, 6.5440e-07],
        [9.9999e-01, 5.9103e-06, 5.6281e-07],
        [1.0000e+00, 2.9204e-06, 3.2853e-07],
        [1.0000e+00, 2.0298e-06, 2.1057e-07],
        [9.9999e-01, 7.4968e-06, 7.9558e-07],
        [1.0000e+00, 3.4189e-06, 3.5638e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.5531e-06, 1.3498e-06],
        [9.9999e-01, 6.2900e-06, 5.1785e-07],
        [9.9999e-01, 4.6125e-06, 5.3167e-07],
        [1.0000e+00, 2.4495e-06, 2.2278e-07],
        [9.9999e-01, 5.1746e-06, 4.3407e-07],
        [9.9999e-01, 4.8115e-06, 6.5725e-07],
        [1.0000e+00, 3.7184e-06, 3.6870e-07],
        [9.9999e-01, 6.1933e-06, 5.5278e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.0004e-06, 4.3662e-07],
        [9.9999e-01, 5.0955e-06, 9.0953e-07],
        [1.0000e+00, 4.0918e-06, 3.5258e-07],
        [9.9999e-01, 4.9782e-06, 3.9568e-07],
        [1.0000e+00, 2.7536e-06, 2.7503e-07],
        [9.9999e-01, 1.0272e-05, 2.1368e-06],
        [1.0000e+00, 4.0119e-06, 4.3180e-07],
        [1.0000e+00, 3.3441e-06, 3.2318e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.0912e-06, 4.7655e-07],
        [1.0000e+00, 3.9226e-06, 4.4066e-07],
        [9.9999e-01, 5.3343e-06, 8.1625e-07],
        [1.0000e+00, 2.8284e-06, 2.7648e-07],
        [9.9999e-01, 4.6582e-06, 4.9204e-07],
        [1.0000e+00, 4.2856e-06, 3.1421e-07],
        [9.9999e-01, 6.6304e-06, 6.6959e-07],
        [9.9999e-01, 7.9733e-06, 1.2303e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.9991e-06, 1.4445e-06],
        [1.0000e+00, 2.9781e-06, 2.8033e-07],
        [1.0000e+00, 4.4060e-06, 4.2303e-07],
        [9.9999e-01, 5.8058e-06, 8.2135e-07],
        [9.9999e-01, 4.9565e-06, 5.2350e-07],
        [9.9999e-01, 4.5733e-06, 5.0228e-07],
        [1.0000e+00, 4.4965e-06, 3.1403e-07],
        [1.0000e+00, 4.4979e-06, 4.1577e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 3.8562e-06, 3.7547e-07],
        [9.9999e-01, 4.9698e-06, 5.4090e-07],
        [1.0000e+00, 3.8007e-06, 4.0765e-07],
        [9.9999e-01, 7.5433e-06, 1.7014e-06],
        [1.0000e+00, 3.5841e-06, 3.7187e-07],
        [9.9999e-01, 5.3687e-06, 5.7528e-07],
        [1.0000e+00, 4.3351e-06, 4.2026e-07],
        [1.0000e+00, 4.4247e-06, 3.7119e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
Train Epoch: 2 [80 (58%)]	Loss: 0.801446	Accuracy: 0.750000
predicted tensor([[1.0000e+00, 3.1250e-06, 3.7523e-07],
        [9.9999e-01, 9.2016e-06, 1.2823e-06],
        [9.9999e-01, 5.0003e-06, 5.3987e-07],
        [1.0000e+00, 3.5709e-06, 3.2910e-07],
        [9.9999e-01, 5.4477e-06, 3.9166e-07],
        [9.9999e-01, 5.4281e-06, 1.1875e-06],
        [9.9999e-01, 4.9283e-06, 5.2320e-07],
        [1.0000e+00, 3.6018e-06, 3.4258e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.6260e-06, 8.9723e-07],
        [1.0000e+00, 3.9431e-06, 3.3160e-07],
        [9.9999e-01, 7.1687e-06, 1.2161e-06],
        [1.0000e+00, 2.4986e-06, 2.0192e-07],
        [1.0000e+00, 3.0507e-06, 2.5062e-07],
        [9.9999e-01, 1.0550e-05, 1.6424e-06],
        [1.0000e+00, 2.9445e-06, 2.9676e-07],
        [9.9999e-01, 5.2104e-06, 8.7714e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.8249e-06, 1.4824e-06],
        [1.0000e+00, 3.3054e-06, 2.8563e-07],
        [1.0000e+00, 3.1092e-06, 3.1958e-07],
        [1.0000e+00, 3.7849e-06, 4.4949e-07],
        [9.9999e-01, 1.0223e-05, 9.2324e-07],
        [9.9999e-01, 6.6346e-06, 9.3890e-07],
        [1.0000e+00, 2.8842e-06, 3.0874e-07],
        [9.9999e-01, 4.8487e-06, 5.1962e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 3.8845e-06, 4.1215e-07],
        [9.9999e-01, 4.9215e-06, 7.3087e-07],
        [9.9999e-01, 6.5709e-06, 8.8871e-07],
        [1.0000e+00, 2.6316e-06, 3.5254e-07],
        [1.0000e+00, 2.9540e-06, 3.3023e-07],
        [9.9999e-01, 8.6534e-06, 6.8652e-07],
        [1.0000e+00, 4.1133e-06, 5.5732e-07],
        [9.9999e-01, 5.3969e-06, 7.2830e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 3.3199e-06, 4.0818e-07],
        [9.9999e-01, 5.8869e-06, 5.9808e-07],
        [9.9999e-01, 5.7581e-06, 9.8433e-07],
        [1.0000e+00, 2.2905e-06, 2.3051e-07],
        [9.9999e-01, 4.3557e-06, 5.4511e-07],
        [9.9999e-01, 5.1939e-06, 9.6010e-07],
        [1.0000e+00, 4.2305e-06, 4.7727e-07],
        [9.9999e-01, 6.4611e-06, 6.3614e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.2553e-06, 3.6504e-07],
        [9.9999e-01, 5.4325e-06, 9.5126e-07],
        [1.0000e+00, 4.2145e-06, 6.1356e-07],
        [9.9999e-01, 6.2525e-06, 1.2241e-06],
        [9.9999e-01, 5.7574e-06, 1.0065e-06],
        [1.0000e+00, 2.5793e-06, 2.4000e-07],
        [9.9999e-01, 5.5262e-06, 8.4081e-07],
        [1.0000e+00, 2.9160e-06, 2.4811e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.4588e-06, 1.3668e-06],
        [1.0000e+00, 3.8794e-06, 3.4796e-07],
        [1.0000e+00, 3.1697e-06, 4.2862e-07],
        [1.0000e+00, 4.2351e-06, 4.7319e-07],
        [9.9999e-01, 5.7378e-06, 7.1505e-07],
        [9.9999e-01, 6.8250e-06, 5.3167e-07],
        [9.9999e-01, 9.8412e-06, 2.0298e-06],
        [1.0000e+00, 1.8334e-06, 3.0241e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.8178e-06, 1.6927e-06],
        [9.9999e-01, 5.2891e-06, 7.3915e-07],
        [1.0000e+00, 3.1452e-06, 4.3066e-07],
        [1.0000e+00, 2.0927e-06, 2.2284e-07],
        [9.9999e-01, 5.3535e-06, 3.5131e-07],
        [9.9999e-01, 7.1714e-06, 1.5872e-06],
        [9.9999e-01, 4.4022e-06, 5.9696e-07],
        [9.9999e-01, 6.6354e-06, 7.7329e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
Train Epoch: 2 [88 (84%)]	Loss: 0.926444	Accuracy: 0.625000
predicted tensor([[1.0000e+00, 4.3512e-06, 4.3788e-07],
        [1.0000e+00, 4.3271e-06, 4.7449e-07],
        [9.9999e-01, 9.2201e-06, 9.9346e-07],
        [9.9999e-01, 5.2987e-06, 1.4190e-06],
        [9.9999e-01, 4.3720e-06, 5.6270e-07],
        [1.0000e+00, 2.6086e-06, 3.3553e-07],
        [1.0000e+00, 4.3045e-06, 5.5586e-07],
        [9.9999e-01, 6.0445e-06, 9.4579e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 2.8782e-06, 2.5200e-07],
        [9.9999e-01, 8.1180e-06, 1.4848e-06],
        [9.9999e-01, 1.1303e-05, 2.5620e-06],
        [1.0000e+00, 2.9979e-06, 3.6972e-07],
        [1.0000e+00, 3.7912e-06, 5.5690e-07],
        [9.9999e-01, 7.8894e-06, 1.3013e-06],
        [9.9999e-01, 5.6542e-06, 5.2687e-07],
        [1.0000e+00, 3.5464e-06, 3.9024e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 4.7127e-06, 5.5121e-07],
        [9.9999e-01, 8.9742e-06, 1.9912e-06],
        [1.0000e+00, 2.8084e-06, 2.6472e-07],
        [1.0000e+00, 4.0731e-06, 4.5159e-07],
        [1.0000e+00, 3.0005e-06, 3.5206e-07],
        [9.9999e-01, 1.0828e-05, 1.7879e-06],
        [9.9999e-01, 5.0079e-06, 8.3461e-07],
        [9.9999e-01, 5.7336e-06, 9.3048e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.9706e-06, 7.4316e-07],
        [1.0000e+00, 3.4300e-06, 6.0012e-07],
        [9.9999e-01, 6.0673e-06, 7.6748e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
iter
(243, 3) (243, 3) (243, 3)
(243,) (243,)
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]
[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]
<function compute_ap at 0x7b0a6fe936d0>
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.] [0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58 0.58
 0.58 0.58 0.58 0.58 0.58]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.] [0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21]
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1.] [0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21
 0.21 0.21 0.21 0.21 0.21]
[[147   0   0]
 [ 45   0   0]
 [ 51   0   0]]
[0.44 0.11 0.13]
map:  0.22534709565143288
predicted tensor([[9.9999e-01, 5.7493e-06, 5.1684e-07],
        [9.9999e-01, 7.9414e-06, 7.9416e-07],
        [9.9999e-01, 6.9804e-06, 1.4768e-06],
        [9.9999e-01, 5.9454e-06, 1.3149e-06],
        [1.0000e+00, 4.0121e-06, 5.5942e-07],
        [9.9999e-01, 4.5474e-06, 6.8229e-07],
        [1.0000e+00, 3.4886e-06, 6.4294e-07],
        [1.0000e+00, 4.0652e-06, 5.3959e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 9.3953e-06, 1.8928e-06],
        [9.9999e-01, 7.1788e-06, 1.5532e-06],
        [9.9999e-01, 6.4261e-06, 1.0432e-06],
        [1.0000e+00, 4.0288e-06, 4.6598e-07],
        [9.9999e-01, 1.0017e-05, 1.9268e-06],
        [1.0000e+00, 2.9693e-06, 3.4266e-07],
        [1.0000e+00, 3.4547e-06, 3.4114e-07],
        [1.0000e+00, 2.9165e-06, 3.8668e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 4.6903e-06, 6.3539e-07],
        [9.9999e-01, 6.1822e-06, 6.0090e-07],
        [9.9999e-01, 8.0056e-06, 1.9504e-06],
        [9.9999e-01, 4.7932e-06, 6.8735e-07],
        [9.9999e-01, 6.3962e-06, 1.2284e-06],
        [9.9999e-01, 6.5683e-06, 1.6967e-06],
        [1.0000e+00, 2.8150e-06, 3.7984e-07],
        [1.0000e+00, 4.0837e-06, 4.9244e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.5070e-06, 8.7059e-07],
        [9.9999e-01, 5.4329e-06, 6.7689e-07],
        [9.9999e-01, 4.3111e-06, 9.4553e-07],
        [9.9999e-01, 1.0525e-05, 2.1532e-06],
        [1.0000e+00, 2.8595e-06, 3.9342e-07],
        [1.0000e+00, 3.6278e-06, 7.3051e-07],
        [9.9999e-01, 8.5809e-06, 1.7975e-06],
        [1.0000e+00, 4.4273e-06, 4.5932e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
Train Epoch: 3 [96 (10%)]	Loss: 0.926443	Accuracy: 0.625000
predicted tensor([[9.9999e-01, 9.5731e-06, 1.2089e-06],
        [1.0000e+00, 3.3560e-06, 5.2041e-07],
        [9.9999e-01, 5.5963e-06, 8.9887e-07],
        [9.9999e-01, 9.3877e-06, 4.1429e-06],
        [1.0000e+00, 3.8401e-06, 6.1994e-07],
        [9.9999e-01, 5.6204e-06, 8.8699e-07],
        [9.9999e-01, 5.1869e-06, 6.8896e-07],
        [9.9999e-01, 5.4303e-06, 6.7044e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 8.4205e-06, 1.6358e-06],
        [9.9999e-01, 9.4881e-06, 1.5684e-06],
        [9.9999e-01, 4.9311e-06, 6.4075e-07],
        [1.0000e+00, 2.1998e-06, 2.3631e-07],
        [9.9999e-01, 6.6448e-06, 1.9360e-06],
        [9.9999e-01, 4.3221e-06, 8.3294e-07],
        [9.9999e-01, 9.7038e-06, 1.9654e-06],
        [9.9999e-01, 4.5738e-06, 6.2581e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 6.7332e-06, 1.9496e-06],
        [9.9999e-01, 6.3827e-06, 7.9011e-07],
        [9.9999e-01, 9.4917e-06, 1.7420e-06],
        [9.9999e-01, 7.2744e-06, 1.6556e-06],
        [9.9999e-01, 7.1295e-06, 1.2770e-06],
        [9.9999e-01, 5.7685e-06, 1.0092e-06],
        [1.0000e+00, 3.4509e-06, 4.7179e-07],
        [1.0000e+00, 2.9537e-06, 4.8321e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.7650e-06, 1.5150e-06],
        [9.9999e-01, 6.0681e-06, 1.1294e-06],
        [9.9999e-01, 5.6139e-06, 1.8412e-06],
        [9.9999e-01, 5.2853e-06, 9.7749e-07],
        [9.9999e-01, 7.6987e-06, 9.9324e-07],
        [9.9999e-01, 7.1239e-06, 1.1940e-06],
        [9.9999e-01, 5.6330e-06, 1.1056e-06],
        [9.9999e-01, 5.8847e-06, 8.1713e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.]], device='cuda:0')
predicted tensor([[1.0000e+00, 3.7885e-06, 6.2916e-07],
        [1.0000e+00, 3.0754e-06, 5.7391e-07],
        [9.9999e-01, 4.5047e-06, 7.8092e-07],
        [9.9999e-01, 9.5791e-06, 2.3195e-06],
        [9.9999e-01, 7.7268e-06, 9.6327e-07],
        [9.9999e-01, 1.1422e-05, 3.4686e-06],
        [9.9999e-01, 8.3010e-06, 2.4108e-06],
        [9.9999e-01, 5.8180e-06, 1.1591e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 9.3421e-06, 1.1320e-06],
        [9.9999e-01, 7.0152e-06, 1.4802e-06],
        [9.9999e-01, 5.5479e-06, 7.9198e-07],
        [9.9999e-01, 7.5541e-06, 2.9667e-06],
        [9.9999e-01, 5.3915e-06, 1.2942e-06],
        [1.0000e+00, 3.5146e-06, 7.7122e-07],
        [9.9999e-01, 8.8246e-06, 2.5762e-06],
        [9.9999e-01, 4.4361e-06, 8.2650e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 1., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 8.1808e-06, 2.9785e-06],
        [1.0000e+00, 3.6008e-06, 5.5361e-07],
        [9.9999e-01, 8.0723e-06, 1.9149e-06],
        [9.9999e-01, 4.5840e-06, 7.1185e-07],
        [9.9999e-01, 7.6712e-06, 1.2357e-06],
        [9.9999e-01, 6.4762e-06, 2.0708e-06],
        [9.9999e-01, 7.1656e-06, 1.7357e-06],
        [9.9999e-01, 4.7699e-06, 1.0564e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 7.5608e-06, 2.1776e-06],
        [9.9999e-01, 4.5341e-06, 1.0908e-06],
        [9.9999e-01, 9.4545e-06, 1.2650e-06],
        [9.9999e-01, 8.7852e-06, 3.8517e-06],
        [1.0000e+00, 3.6314e-06, 7.8209e-07],
        [9.9999e-01, 3.9359e-06, 1.3570e-06],
        [9.9999e-01, 6.5316e-06, 1.0693e-06],
        [9.9999e-01, 7.0430e-06, 1.7779e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.]], device='cuda:0')
Train Epoch: 3 [104 (35%)]	Loss: 1.051442	Accuracy: 0.500000
predicted tensor([[9.9999e-01, 5.7417e-06, 1.5516e-06],
        [9.9999e-01, 4.9343e-06, 1.0035e-06],
        [9.9998e-01, 1.5115e-05, 6.6515e-06],
        [9.9999e-01, 7.8790e-06, 2.2190e-06],
        [1.0000e+00, 3.4634e-06, 6.9784e-07],
        [9.9999e-01, 8.9724e-06, 2.5752e-06],
        [9.9999e-01, 4.6516e-06, 1.1186e-06],
        [9.9999e-01, 4.3963e-06, 9.5353e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9998e-01, 1.2388e-05, 5.5039e-06],
        [9.9999e-01, 7.5850e-06, 1.5295e-06],
        [9.9999e-01, 4.6608e-06, 1.3743e-06],
        [9.9999e-01, 5.5705e-06, 1.2176e-06],
        [9.9998e-01, 1.0478e-05, 5.2926e-06],
        [9.9999e-01, 4.7928e-06, 1.1728e-06],
        [9.9999e-01, 5.0634e-06, 1.1657e-06],
        [1.0000e+00, 3.1642e-06, 6.8808e-07]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[0., 0., 1.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 5.0429e-06, 1.3647e-06],
        [1.0000e+00, 3.2589e-06, 7.3817e-07],
        [9.9999e-01, 1.1413e-05, 2.4579e-06],
        [9.9998e-01, 1.3214e-05, 5.7782e-06],
        [9.9999e-01, 7.5678e-06, 4.0213e-06],
        [9.9999e-01, 4.9444e-06, 1.4438e-06],
        [9.9999e-01, 5.0264e-06, 1.2229e-06],
        [9.9999e-01, 4.5540e-06, 1.5280e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [1., 0., 0.],
        [0., 1., 0.],
        [0., 0., 1.],
        [0., 0., 1.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.]], device='cuda:0')
predicted tensor([[9.9999e-01, 4.2360e-06, 1.3756e-06],
        [9.9999e-01, 8.0407e-06, 2.2232e-06],
        [9.9999e-01, 5.2722e-06, 1.6323e-06],
        [9.9999e-01, 4.3836e-06, 1.3709e-06],
        [9.9999e-01, 7.1962e-06, 3.0403e-06],
        [9.9998e-01, 1.3836e-05, 5.7837e-06],
        [9.9999e-01, 3.8022e-06, 1.2310e-06],
        [9.9999e-01, 9.6515e-06, 2.9896e-06]], device='cuda:0',
       grad_fn=<SoftmaxBackward0>)
target tensor([[1., 0., 0.],
        [0., 1., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
        [1., 0., 0.],
